# Read the data
dataPath<-"C:/Users/Public/Documents"
train_dat <- read.table(paste(dataPath,'Week6_Test_Sample_Train.csv',sep = '/'), header=TRUE)
main_dat <- read.table(paste(dataPath,'Week6_Test_Sample_Test.csv',sep = '/'), header=TRUE)


n_train <- length(train_dat[,1])
head(train_dat)

plot(train_dat[,2],train_dat[,1], type="p",pch=19)

# Define training samples generated by model 1 and model 2 ---------------------
train_1<-cbind(train_dat[,2],rep(NA,n_train))
train_2<-cbind(train_dat[,2],rep(NA,n_train))

train_1[train_dat[,3]*(1:n_train),2]<-
  train_dat[train_dat[,3]*(1:n_train),1]

train_2[(1-train_dat[,3])*(1:n_train),2]<-
  train_dat[(1-train_dat[,3])*(1:n_train),1]

head(cbind(train_dat,
           Trainig1=train_1[,2],
           Training2=train_2[,2]))

matplot(train_dat[,2],cbind(train_1[,2],train_2[,2]),
        pch=16,col=c("green","blue"),ylab="Subsamples of the training sample")



# Estimate the linear model ----------------------------------------------------
EstimatedLinearModel.Training <- lm(Output ~ Input, train_dat)
summary(EstimatedLinearModel.Training)$coefficients

# Get the residuals
EstimatedResiduals.Training<-EstimatedLinearModel.Training$residuals
plot(train_dat[,2],EstimatedResiduals.Training)


# Define residuals corresponding to different models 
EstimatedResiduals.Training.1<-EstimatedResiduals.Training
EstimatedResiduals.Training.2<-EstimatedResiduals.Training
EstimatedResiduals.Training.1[(train_dat[,3]==0)*(1:n_train)]<-NA
EstimatedResiduals.Training.2[(train_dat[,3]==1)*(1:n_train)]<-NA

# Print the first ten columns to check the separation 
head(cbind(AllResiduals=EstimatedResiduals.Training,
           Training1Residuals=EstimatedResiduals.Training.1,
           Training2Residuals=EstimatedResiduals.Training.2,
           TrainingClass=train_dat[,3]))


# Plot the residuals corresponding to different models
matplot(train_dat[,2],cbind(EstimatedResiduals.Training.1,
                                       EstimatedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Separated parts of the training sample")



# Create the data frame for logistic regression --------------------------------
Logistic.Model.Data<-data.frame(Logistic.Output=train_dat[,3],
                                Logistic.Input=EstimatedResiduals.Training)
LinearModel.Training.Logistic<-glm(Logistic.Output~Logistic.Input,data=Logistic.Model.Data,
                                   family=binomial(link=logit))
summary(LinearModel.Training.Logistic)


Predicted.Probabilities.Training<-predict(LinearModel.Training.Logistic,type="response")
plot(train_dat[,2],Predicted.Probabilities.Training)




# Create the unscrambling sequence for the training sample ---------------------
Unscrambling.Sequence.Training.Logistic<-
  (predict(LinearModel.Training.Logistic,type="response")>.5)*1
# Create classified residuals
ClassifiedResiduals.Training.1<-EstimatedResiduals.Training
ClassifiedResiduals.Training.2<-EstimatedResiduals.Training
ClassifiedResiduals.Training.1[(Unscrambling.Sequence.Training.Logistic==0)*
                                 (1:n_train)]<-NA
ClassifiedResiduals.Training.2[(Unscrambling.Sequence.Training.Logistic==1)*
                                 (1:n_train)]<-NA
head(cbind(AllTraining=EstimatedResiduals.Training,
           Training1=ClassifiedResiduals.Training.1,
           Training2=ClassifiedResiduals.Training.2))


# Plot both classes of the residuals
matplot(train_dat[,2],cbind(ClassifiedResiduals.Training.1,
                                       ClassifiedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Classified residuals, X-axis at 0")
axis(1,pos=0)



# calculate the classification rule --------------------------------------------
beta0 <- LinearModel.Training.Logistic$coefficients[1]
beta1 <- LinearModel.Training.Logistic$coefficients[2]


Classification.Rule.Logistic <- -beta0/beta1

matplot(train_dat[,2],cbind(ClassifiedResiduals.Training.1,
                                       ClassifiedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Classified residuals, X-axis at the rule level")
axis(1,pos=Classification.Rule.Logistic)




# Separate subsamples in the main sample ---------------------------------------
# using the classifier trained on the training sample

head(main_dat)

EstimatedLinearModel<-lm(Output ~ Input, main_dat)
EstimatedLinearModel$coefficients

EstimatedResiduals<-EstimatedLinearModel$residuals
plot(main_dat[,2],EstimatedResiduals)


Unscrambling.Sequence.Logistic <- 
  (predict(LinearModel.Training.Logistic,
           newdata=data.frame(Logistic.Output=EstimatedResiduals,
                              Logistic.Input=EstimatedResiduals),
           type="response") > .5)*1

LinearModel.Training.Logistic$coefficients
lp <- EstimatedResiduals[1]*LinearModel.Training.Logistic$coefficients[2] + LinearModel.Training.Logistic$coefficients[1]
pFailure <- exp(lp)/(1+exp(lp))

Unscrambling.Sequence.Logistic

Probability<-sum(Unscrambling.Sequence.Logistic)/length(Unscrambling.Sequence.Logistic)
Probability

n_main <- length(main_dat[,1])

binom.test(sum(Unscrambling.Sequence.Logistic), n_main, p = 0.5,
           alternative = "two.sided",
           conf.level = 0.95)


# Create classified residuals --------------------------------------------------
ClassifiedResiduals.1<-EstimatedResiduals
ClassifiedResiduals.2<-EstimatedResiduals
ClassifiedResiduals.1[(Unscrambling.Sequence.Logistic==0)*(1:n_main)]<-NA
ClassifiedResiduals.2[(Unscrambling.Sequence.Logistic==1)*(1:n_main)]<-NA
# Print first 10 rows to check
cbind(EstimatedResiduals,ClassifiedResiduals.1,ClassifiedResiduals.2)[1:10,]


# Plot both classes of the residuals
matplot(main_dat[,2],cbind(ClassifiedResiduals.1,
                              ClassifiedResiduals.2),
        pch=16,col=c("green","blue"),ylab="Classes of the main sample, X-axis at 0")
axis(1,pos=0)



matplot(main_dat[,2],cbind(ClassifiedResiduals.1,ClassifiedResiduals.2),
        pch=16,col=c("green","blue"),ylab="Classes of the main sample, X-axis at the rule level")
axis(1,pos=Classification.Rule.Logistic)



# Create recovered models ------------------------------------------------------
LinearModel1.Recovered <- main_dat
LinearModel2.Recovered <- main_dat
LinearModel1.Recovered[(1-Unscrambling.Sequence.Logistic)*(1:n_main),1]<-NA
LinearModel2.Recovered[Unscrambling.Sequence.Logistic*(1:n_main),1]<-NA

# Print the first 1 rows of scrambled and unscrambled samples
cbind(main_dat,LinearModel1.Recovered,LinearModel2.Recovered)[1:10,]


# Plot the unscrambled subsamples
matplot(main_dat[,2],cbind(LinearModel1.Recovered[,1],LinearModel2.Recovered[,1]), 
        type="p",col=c("green","blue"),pch=19,ylab="Separated Subsamples")


LinearModel1.Recovered.lm<-lm(LinearModel1.Recovered[,1]~LinearModel1.Recovered[,2])
LinearModel2.Recovered.lm<-lm(LinearModel2.Recovered[,1]~LinearModel2.Recovered[,2])

summary(LinearModel1.Recovered.lm)
summary(LinearModel2.Recovered.lm)


# Plot residuals
Residuals.Comparison <- cbind(Unscrambled.residuals = 
                                c(summary(LinearModel1.Recovered.lm)$residuals,
                                  summary(LinearModel2.Recovered.lm)$residuals),
                              Single.Model.residuals=EstimatedResiduals)

matplot(Residuals.Comparison,
        type="p",pch=16,ylab="Residuals before and after unscrabling")






# Save the result
res <- list(Unscrambling.Sequence.Logistic =  Unscrambling.Sequence.Logistic)
write.table(res, file = paste(dataPath,'result.csv',sep = '/'), row.names = F)
